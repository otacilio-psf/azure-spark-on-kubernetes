apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: spark-job-igti-desafio
  namespace: processing
spec:
  type: Python
  mode: cluster
  image: "docker.io/otaciliopsf/cde-bootcamp:desafio-mod4"
  imagePullPolicy: Always
  mainApplicationFile: "local:///opt/spark/work-dir/app.py"
  deps:
    pyFiles:
       - local:///opt/spark/work-dir/dimensao_cursos.csv
       - local:///opt/spark/work-dir/dimensao_municipio.csv
       - local:///opt/spark/work-dir/schema.py
  sparkVersion: "3.1.1"
  sparkConf:
    "spark.sql.extensions": "io.delta.sql.DeltaSparkSessionExtension"
    "spark.sql.catalog.spark_catalog": "org.apache.spark.sql.delta.catalog.DeltaCatalog"
  restartPolicy:
    type: Never
  driver:
    envFrom:
      - configMapRef:
          name: lake-config
    envSecretKeyRefs:
      AZURE_CLIENT_ID:
        name: azure-service-account
        key: AZURE_CLIENT_ID
      AZURE_CLIENT_SECRET:
        name: azure-service-account
        key: AZURE_CLIENT_SECRET
      AZURE_TENANT_ID:
        name: azure-service-account
        key: AZURE_TENANT_ID
      STG_ACC_NAME:
        name: lake-config
        key: storage_account_name
      LAKE_NAME:
        name: lake-config
        key: file_system_name
    cores: 1
    coreLimit: "1200m"
    memory: "1g"
    labels:
      version: 3.1.1
    serviceAccount: spark
  executor:
    cores: 1
    instances: 3
    memory: "2g"
    labels:
      version: 3.1.1